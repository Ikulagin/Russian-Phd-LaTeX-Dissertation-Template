%!!!!!ДЛЯ ВВедения Вопрос эффективности является ключевым для организации высокопроизводительных вычислений. Для организации эффективных вычислений требуется выполнять оптимизацию на всех стадиях разработки программ. Знание ключевых концепций микроархитектуры целевого процессора помогают принимать решения при оптимизации программного обеспечения. Кроме того, понимание базовых аспектов организации архитектуры и микроархитектуры процессора позволяет выполнить оценку приблизительного ускорения вычислений, что необходимо при выборе аппаратного обеспечения под конкретное приложение.

\chapter{Оптимизация выполнения программ на многопроцессорных ВС с общей памятью} \label{part3}
В данной главе рассматриваются методы оптимизации выполнения параллельных программ на многопроцессорных ВС с общей памятью. Рассматриваемые методы ориентированны на повышение эффективности синхронизации потоков параллельных программ и оптимизацию выполнения циклических конструкций, в частности, конвейеризацию и векторизацию циклов. Описан алгоритм оптимизации обнаружения конфликтов при выполнении синхронизации потоков с помощью программной транзакционной памяти. Алгоритм основан на предварительном профилировании параллельной программы. Для профилирования предложен инструментарий, позволяющий получать информацию о динамических свойствах транзакционных секций программы.

\section{Обзор методов синхронизации на ВС с общей памятью}
\subsection{Понятие состояния гонки за данными}
При выполнении многопоточной программы на ресурсах многопроцессорной ВС с общей памятью может возникнуть \textit{состояние гонки за данными} (\textit{data race}) -- это такая ситуация при которой множество потоков пытаются одновременно получить доступ к разделяемому ресурсу, к одной области памяти. Возникновение состояние гонки за данными является результатом ошибки при разработки параллельного алгоритма и приводит к некорректной работе программы.

Пусть имеются два потока $A$ и $B$, которые одновременно выполняют код $C_{A}$ и $C_{B}$. В коде выполняется операция чтения над ячейками памяти из множества $R(A)$ -- для потока $A$ и $R(B)$ -- для потока $B$. Со считанными из ячеек памяти значениями выполняются арифметические и логические операции, результат которых при помощи операции записи сохраняется во множество ячеек памяти $W(A)$ -- для потока $A$ и $W(B)$ -- для потока $B$. Таким образом, множество $\{R(A) \cup W(A) \}$ -- есть множество используемых в коде $C_{A}$ ячеек памяти потоком $A$, а множество $\{R(B) \cup W(B) \}$ -- множество используемых в коде $C_{B}$ ячеек памяти потоком $B$.

В этом случае \textit{состояние гонки за данными} возникает, если не выполняется хотя бы одно из условий Бернстайна \todo{ССЫЛКА}:
\begin{enumerate}
\item $R(A) \cap W(B) = \emptyset$
\item $W(A) \cap R(B) = \emptyset$
\item $W(A) \cap W(B) = \emptyset$
\end{enumerate}

Большинство современных языков программирования имеют возможность создания \textit{потоков} (\textit{threads}) тем самым, реализуя модель многопоточного программирования. В случае, если два или более потоков одновременно будут обращаться к данным, хранимым в одной и той же ячейке памяти, и как минимум один из них будет выполнять операцию записи, возникает состояние гонки за данными. В Листинге~\ref{list:openmp_datarace.c} представлен фрагмент OpenMP-программы на языке С, в которой возникает состояния гонки за данными. Этот фрагмент кода содержит распараллеленный при помощи OpenMP директив цикл из \texttt{n} итераций. В теле цикла накапливается сумма \texttt{summ} значений \texttt{a}, возвращаемых функцией \texttt{func(i)}. Так как доступ к общей переменной \texttt{summ} выполняется одновременно несколькими потоками, то выполнение данного кода приведет к возникновению состояния гонки за данными.

\begin{ListingEnv}[!h]
	\lstinputlisting[style=customc]{listings/openmp_datarace.c}
    \caption{Фрагмент OpenMP-программы, приводящей к возникновению состояния гонки за данными}
    \label{list:openmp_datarace.c}
\end{ListingEnv}

Возникновение состояний гонки за данными является одним из негативных явлений многопоточной модели параллельного программирования. Для их предотвращения используются следующие подходы к созданию потокобезопасных программ:
\begin{itemize}
\item синхронизация потоков при помощи операций блокировок \todo{ССЫЛКИ}
\item неблокирующая синхронизация???(или разработка алгоритмов и структур данных свободных от блокировок) \todo{ССЫЛКИ}
\item использование транзакционной памяти. \todo{ССЫЛКИ}
\end{itemize}
Кроме исследований в области разработки средств создания потокобезопасных программ в мире активно ведутся работы по разработке средств автоматического обнаружения гонок \todo{ССЫЛКИ}.

\subsection{Синхронизация потоков при помощи операций блокировок}
Для предотвращения возникновения состояния гонок за данными необходимо синхронизировать доступ потоков к общей области памяти. Один из активно используемых подходов к синхронизации потоков заключается в использовании операций блокировок. Этот подход позволяет создавать в коде программы \textit{критические секции} -- участки кода, выполнение которых возможно только одним потоком в каждый момент времени. Последовательное выполнение критических секций достигается при помощи механизма \textit{взаимного исключения} (\textit{mutual exclusion}).

В основе механизма взаимного исключения лежат две операции \texttt{lock} и \texttt{unlock}, выполняемые над специальным объектом -- \textit{мьютексом} (\textit{mutex}). Операция \texttt{lock} выполняется при входе в критическую секцию и помечает мьютекс как <<\textit{занят}>>, а операция \texttt{unlock} -- при выходе, и помечает мьютекс как <<\textit{свободен}>>. Операцию \texttt{lock} принято называть захватом мьютекса, а операцию \texttt{unlock} -- освобождением.

Пусть имеется поток $A$ и поток $B$, а также логические переменные $F$ и $S$, сигнализирующие о выполнении критической секции $C$. Если поток $A$ выполняет критическую секцию $C$, то логическая переменная $F$ принимает значение \textit{ИСТИНА}, а если критическую секцию выполняет поток $B$, то значение \textit{ИСТИНА} принимает логическая переменная $S$. Механизм взаимного исключения в любой момент времени для критической секции $C$ обеспечивает выполнение следующего условия:
\begin{equation}
  \label{eq:mutex_condition}
  \neg(A \land B) = \textit{ИСТИНА}
\end{equation}

\begin{ListingEnv}[!h]
	\lstinputlisting[style=customc]{listings/pthread_mutex_exm.c}
    \caption{Фрагмент программы, использующей механизм взаимного исключения для создания критической секции}
    \label{list:pthread_mutex_exm.c}
\end{ListingEnv}

В Листинге~\ref{list:pthread_mutex_exm.c} приведен пример создания критической секции при помощи механизма взаимного исключения. В этом примере функция \texttt{thread\_body} выполняется множеством потоков. Каждый поток выполняет цикл со своим пространством итераций, в теле которого накапливается сумма возвращаемого значения функции \texttt{func}. Доступ к разделяемой переменной \texttt{summ} осуществляется внутри критической секции, организованной механизмом взаимного исключения при помощи мьютекса \texttt{m}. При входе в критическую секцию, для захвата мьютекса, поток должен выполнить функцию \texttt{pthread\_mutex\_lock}, а при выходе из критической секции, для освобождения мьютекса, -- \texttt{pthread\_mutex\_unlock}. Эти функции предоставляются библиотекой стандарта POSIX -- \textit{Pthreads}, реализующей операции по созданию и управлению потоками.

Операции \texttt{lock} и \texttt{unlock} должны обеспечивать выполнения условия \ref{eq:mutex_condition}, и реализуются на основе атомарной операции \textit{сравнение с обменом} (\textit{compare and swap} -- \textit{CAS}). В Листинге~\ref{list:CAS.pc} приведен псевдокод алгоритма операции CAS, выполняющая запись значения третьего аргумента в первый аргумент, в случае, если значение второго аргумента и первого равны. В противном случае во второй аргумент записывается значение первого аргумента. Атомарная операция CAS предоставляется архитектурой набора команд большинства процессоров, например, архитектуры IA-32/Intel 64 реализуют команду сравнение с обменом -- \texttt{cmpxchg}, которая совместно с префиксом \texttt{lock} (\texttt{lock cmpxchg}) выполняется атомарно.

\begin{algorithm}[!h]
	\input{listings/CAS.pc}
    \caption{Алгоритм операции \texttt{CAS}}
    \label{list:CAS.pc}
\end{algorithm}

На эффективность выполнения критических секций значимое влияние оказывает алгоритм реализации операции \texttt{lock}. Наиболее распространенными являются: алгоритм циклической блокировки (\textit{spinlock}), алгоритм с использованием фьютекса (\textit{futex}) и адаптивный алгоритм. В частности, вышеперечисленные алгоритмы используются для реализации мьютекса в библиотеки стандарта  POSIX -- \textit{Pthreads}, являющейся частью стандартной библиотеки языка С -- \textit{glibc}.

\begin{algorithm}[!h]
	\input{listings/mutex_spinlock.pc}
    \caption{Алгоритм реализации операций над мьютексом методом циклической блокировкой \textit{spinlock}}
    \label{list:mutex_spinlock.pc}
\end{algorithm}

Листинг~\ref{list:mutex_spinlock.pc} содержит псевдокод функции \texttt{lock}, реализованной алгоритмом циклической блокировки мьютекса и псевдокод фунции \texttt{unlock}. При выполнении операции \texttt{lock} данным алгоритмом, поток в цикле пытается захватить мьютекс \texttt{m}, установив в него значение равное 1 при помощи атомарной операции \texttt{CAS}. Для освобождения мьютекса (операция \texttt{unlock}) значение мьютекса необходимо установить равное 0. Активное ожидание освобождения мьютекса является главным недостатком данного алгоритма, так как в случае, если мьютекс защищает объемную критическую секцию, то процессорное ядро, на котором выполняется ожидающий поток, будет выполнять пустую работу (команда \texttt{NOP} -- \textit{No operation}). Кроме того, частое использование префикса \texttt{lock} в операции \texttt{CAS}, а так же частое обращение к разделяемой области памяти, в которой хранится мьютекс, могут привести к снижению эффективности параллельной программы.

\begin{algorithm}[!h]
	\input{listings/mutex_futex.pc}
    \caption{Алгоритмом реализации операций над мьютексом с использованием фьютекса (\textit{futex})}
    \label{list:mutex_futex.pc}
\end{algorithm}

Алгоритм операции захвата мьютекса с использованием фьютекса и алгоритм его освобождение приведен в Листинге~\ref{list:mutex_futex.pc}. При использовании этого алгоритма поток выполняет одну попытку захватить мьютекс при помощи операции \texttt{CAS}, если ему это не удаётся, то поток переводится в спящее состояние при помощи функции \texttt{FUTEX\_WAIT}. Функция \texttt{FUTEX\_WAIT}, принимающая два аргумента: мьютекс и его ожидаемое значение, вытесняет текущий поток из очереди планирования планировщика в ядре ОС и переводит его в спящее состояние. Пробуждение потока и его постановка в очередь планирования происходит только после того, как передаваемый первым аргументом мьютекс не примет значение передаваемое вторым аргументом, в данном случае 0 -- значение при котором мьютекс \texttt{m} свободен. Операция \texttt{unlock} освобождения мьютекса устанавливает его значение равное 0 и вызывает функцию \texttt{FUTEX\_WAKE} для пробуждения спящих потоков, если такие имеются. Функция \texttt{FUTEX\_WAKE} принимает два аргумента: мьютекс, изменение которого ожидают спящие потоки, и количество пробуждаемых потоков. В данном случае пробуждается 1 поток. Этот алгоритм рекомендуется использовать в программах с большими критическими секциями. В случае небольшой критической секции этот алгоритм может привести существенным накладным расходам на выполнение системных вызовов \texttt{FUTEX\_WAIT} и \texttt{FUTEX\_WAKE}.

\begin{algorithm}[!h]
	\input{listings/mutex_adaptive.pc}
    \caption{Адаптивный алгоритм реализации операций на мьютексом}
    \label{list:mutex_adaptive.pc}
\end{algorithm}

В Листинге~\ref{list:mutex_adaptive.pc} приведен псевдокод адаптивного алгоритма операций захвата мьютекса \texttt{lock} и освобождения \texttt{unlock}. Отличительной особенностью данного алгоритма от предыдущего (Листинг~\ref{list:mutex_futex.pc}), является то, что выполняющий захват мьютекса поток переходит в спящее состояние не сразу после первой неудавшейся попытки выполнить операцию \texttt{CAS}, а по истечению \texttt{attempts} попыток. Выбор оптимального значения для параметра \texttt{attempts} осуществляется на основании динамических характеристик программы и свойств критических секций, для этого могут использоваться методы оптимизации по результатам предварительного профилирования (\textit{profile guided optimization} -- \textit{PGO}), а также различные методы статического анализа кода на этапе компиляции программы. Данная тема представляет интерес и нуждается в дополнительном исследовании.

\subsection{Неблокирующие алгоритмы и структуры данных}
Неблокирующая синхронизация выполнения потоков параллельной программы является одним из способов организации потокобезопасной работы с разделяемыми структурами данных, такими как массивы, списки, хеш-таблицы, деревья и др. при помощи алгоритмов, свободных от блокировок.

\textit{Алгоритмы, свободные от блокировок} (\textit{lock-free algorithms}) -- это потокобезопасный алгоритм, на каждом шаге которого гарантируется успешное выполнение хотя бы одного потока из множества выполняемых шаги этого алгоритма. Таким образом, алгоритм содержащий критическую секцию, выполнение которой возможно только после успешного захвата мьютекса, не является свободным от блокировок. Так как в случае, если захвативший мьютекс поток по каким-то причинам не сможет выполнить критическую секцию, например, будет вытеснен планировщиком операционной системы, то ни один другой поток не сможет её выполнить. В алгоритмах без блокировок такая ситуация исключена.

\begin{algorithm}[!h]
	\input{listings/lock-free_stack_push.pc}
    \caption{Lock-free алгоритм операции \texttt{PUSH} помещения элемента в стек}
    \label{list:lock-free_stack_push.pc}
\end{algorithm}

Пусть имеется потокобезопасный стек $S$ на основе двусвязного списка. В этот стек несколько потоков одновременно пытаются поместить элемент $x$ при помощи операции \texttt{PUSH}, которая реализована свободным от блокировок алгоритмом. В Листинге~\ref{list:lock-free_stack_push.pc} представлен псевдокод алгоритма такой операции. Тогда каждый поток выполняет цикл \texttt{do-while} до тех пор, пока операция \texttt{CAS} на завершится успешно. Если операция \texttt{CAS} завершилась не успешно и поток повторяет выполнение цикл снова, то это значит, что какой-то другой поток успешно выполнил операцию \texttt{PUSH}. Таким образом гарантируется успешное выполнение операции хотя бы одним потоком, что и является обязательным для алгоритмов, свободных от блокировок.

Алгоритмы и структуры данных, свободные от блокировок являются актуальной темой в области исследования перспективных подходов к созданию потокобезопасных масштабируемых программ над которой ведется активная работа \todo{ССЫЛКИ}. Однако, недостатками данного способа является высокая сложность разработки и отладки параллельных программ и ограниченность его применения. Несмотря на то, что неблокирующие алгоритмы и структуры данных полностью избавляют от возможности возникновения \textit{взаимной блокировки} (\textit{deadlock}), они не избавляют от возможности появления \textit{активной блокировки} (\textit{livelock}).

\subsection{Транзакционная память}
\textit{Транзакционная память} (\textit{Transactional memory}) -- это один из примитивов синхронизации потоков, позволяющий предотвратить возникновение состояния гонок за данными без использования блокировок. В отличие от примитивов синхронизации на основе блокировок, транзакционная память позволяет защитить \textit{область память программы} от конкурентного доступа множества потоков, а не участок кода от одновременного выполнения. Использование транзакционной памяти существенно упрощает процесс разработки потокобезопасных программ и позволяет избежать ошибок синхронизации. Отсутствие операций блокировок хорошо сказывается на масштабируемости и эффективности параллельных программ. Существуют как программные реализации транзакционной памяти (\textit{software transactional memory} -- \textit{STM}): LazySTM, TinySTM, GCC TM, DTMC, RSTM, STMX, STM Monad, так и аппаратные реализации в процессорах (\textit{hardware transactional memory} -- \textit{HTM}): Intel TSX, AMD ASF, Oracle Rock, IBM POWER8, IBM PowerPC A2.

Транзакционная память предоставляет языковые конструкции или API позволяющие выделять в программе участки кода, в которых осуществляется защита совместно используемых областей памяти. Такие участки кода принято называть \textit{транзакционными секциями} (\textit{transactional section}), а их выполнение осуществляется без блокирования потоков. В случае, если в целевом процессоре не реализована аппаратная транзакционная память, то задачи по контролю за корректностью выполнения транзакций ложится на среду выполнения (runtime). Если же поддержка HTM реализована, то корректность выполнения (например, отсутствие состояний гонок за данными) обеспечивается процессором, чаще всего на уровне работы кэш-памяти при помощи модифицированного протокола когерентности кэшей -- \textit{TMESI}\todo{ССЫЛКА}.  Если во время выполнения транзакции одним потоком произошло изменение защищаемой области памяти другими потоками, то транзакция считается некорректной. В этом случае, при помощи аппаратных возможностей процессора либо runtime-системы, выполнение транзакции прерывается, все модифицированные в рамках неё области памяти восстанавливаются в исходное состояние, и поток начинает выполнять её заново.

\section{Программная транзакционная память}
\subsection{Основные понятия STM}
Программная транзакционная память предоставляет операции начала транзакции -- \texttt{BeginTransaction}, её принудительного завершения -- \texttt{AbortTransaction} и конца транзакции -- \texttt{CommitTrasnaction}, позволяющие создавать в коде программы транзакционные секции. Для их выполнения runtime-система языка создаёт транзакции. \textit{Транзакция} (\textit{transaction}) -- это конечная последовательность операций транзакционного чтения/записи памяти. Операция \textit{транзакционного чтения} выполняет копирование содержимого указанного участка общей памяти в соответствующий участок локальной памяти потока. \textit{Транзакционная запись} копирует содержимое указанного участка локальной памяти в соответствующий участок общей памяти, доступной всем потокам.

Инструкции транзакций выполняются потоками параллельно (конкурентно). После завершения выполнения транзакция может быть либо \textit{зафиксирована} (commit), либо \textit{отменена} (cancel). Фиксация транзакции подразумевает, что все сделанные в рамках нее изменения памяти становятся необратимыми. При отмене транзакции ее выполнение прерывается, а состояние всех модифицированных областей памяти восстанавливается в исходное с последующим перезапуском транзакции (\textit{откат транзакции}, rollback).

Отмена транзакции происходит в случае обнаружения \textit{конфликта} -- ситуации, при которой два или более потока обращаются к одному и тому же участку памяти, и как минимум один из них выполняет операцию записи.

Для разрешения конфликта разработаны различные походы, например, можно приостановить на некоторое время или отменить одну из конфликтующих транзакций.

\begin{ListingEnv}[!h]
	\lstinputlisting[style=customc]{listings/transactional_section_exm.pc}
    \caption{Добавление пары $(key, value)$ в хеш-таблицу $h$}
    \label{list:transactional_section_exm.pc}
\end{ListingEnv}

В Листинге~\ref{list:transactional_section_exm.pc} представлен пример создания транзакционной секции, в теле которой выполняется добавление элемента в хеш-таблицу множеством потоков. После выполнения тела транзакционной секции каждый поток приступит к выполнению кода, следующего за ней, в случае отсутствия конфликтов. В противном случае поток повторно будет выполнять транзакцию до тех пор, пока его транзакция не будет успешно зафиксирована.

\subsection{Реализация программной транзакционной памяти}
Реализация программной транзакционной памяти требует изменений трех основных составляющих:
\begin{itemize}
\item стандарт языка программирования
\item компилятор
\item runtime-библиотека.
\end{itemize} 

\todo{Может быть вставить рисунок. Стек ПО организации работы STM}

Поддержка STM в стандарте языка программирования требует наличия ключевых слов для создания транзакционных секций в коде, а также, наличия описания семантики использования транзакционной памяти в параллельных программах. Поэтому, международным комитетом ISO по стандартизации языка C++, в рамках рабочей группы WG21, ведутся работы по внедрению транзакционной памяти в стандарт языка. На сегодняшний день предложен черновой вариант спецификации поддержки транзакционной памяти в С++ \cite{luchango_maurer_moir}. Она предоставляет ключевые слова \texttt{\_\_transaction\_atomic}, \texttt{\_\_transaction\_relaxed} для создания транзакционных секций, а также \texttt{\_\_transaction\_cancel} для принудительной отмены транзакции. Эти конструкции также возможно использовать и в программах на языке С.

Компилятор, поддерживающий языковые конструкции для создания транзакционных секций, принято называть \textit{STM-компилятором}. STM-компилятор преобразует языковые конструкции транзакционной памяти в последовательность вызовов функций runtime-библиотеки или в специальные ассемблерные инструкции, если целевой процессор поддерживает аппаратную транзакционную память. Для языков программирования С/С++ поддержка STM реализована в таких компиляторах как: GCC, начиная с версии 4.7, Intel C++ Compiler, и др.

Runtime-библиотека STM отслеживает попытки одновременного доступа к одной и той же области памяти, тем самым осуществляя обнаружение конфликтов. Кроме этого, runtime-библиотека организует использование возможностей аппаратной транзакционной памяти, если целевой процессор её поддерживает. В компиляторе GCC реализована библиотека \texttt{libitm}, которая содержит несколько алгоритмов работы STM, в том числе и алгоритм, основанный на использовании аппаратной транзакционной памяти. Для обеспечения архитектурной и платформенной переносимости программ, использующих STM, компания Intel разработала спецификацию ABI (\textit{aplication binary interface}, \textit{бинарный интерфейс приложений}) для STM-компиляторов и runtime-систем -- Intel TM ABI. Компилятор GCC и библиотека \texttt{libitm} реализуют этот ABI.

\subsection{Алгоритмы работы программной транзакционной памяти}
Алгоритм работы программной транзакционной памяти реализуется runtime-системой и определяет:
\begin{itemize}
\item способ хранения информации о состоянии защищаемых областей памяти
\item политика обновления объектов в памяти
\item стратегия обнаружения конфликтов
\item метод разрешения конфликтов.
\end{itemize}

Для обнаружения конфликтов, runtime-система языка отслеживает попытки одновременного доступа к одной и той же области памяти. Это реализуется путем поддержки информации о состоянии защищаемых регионов памяти. Возможны два уровня гранулярности контролируемых областей: \textit{уровень программных объектов} (\textit{object-based STM}) и \textit{уровень слов памяти} (\textit{word-based STM}).

Уровень программных объектов подразумевает поддержку runtime-системой метаданных о состоянии каждого объекта программы. Например, объектов в С++-программе.

Для реализации уровня слов памяти в простейшем случае требуется каждый байт линейного адресного пространства процесса сопровождать метаданными, что является практически невозможным. Вместо этого линейное адресное пространство процесса разбивается на фиксированные блоки, каждый из которых сопровождается метаданными о состоянии (подход, подобный прямому отображению физических адресов на кэш-память процессора) \cite{felber_fetzer_marlier_riegel, riegel_felber_fetzer}. Это приводит к тому, что множеству областей памяти соответствуют одни метаданные, что является источником возникновения ложных конфликтов. \textit{Ложный конфликт} (\textit{false conflict}) -- это ситуация, при которой два или более потока во время выполнения транзакции обращаются к разным участкам линейного адресного пространства, но отображаемым на одни и те же метаданные. Поэтому runtime-система воспринимает такую ситуацию как конфликт (data race), хотя на самом деле таковой отсутствует. Ложные конфликты существенно снижают эффективность параллельных STM-программ. Поэтому остро стоит задача разработки алгоритмов обнаружения и сокращения числа ложных конфликтов в реализациях STM.

Политика обновления объектов в памяти определяет, когда изменения объектов в рамках транзакции будут записаны в память. Распространение получили две основные политики -- ленивая и ранняя. \textit{Ленивая} политика обновления объектов в памяти (lazy version management) откладывает все операции с объектами до момента фиксации транзакции. Все операции записываются в специальном журнале (redo log), который при фиксации используется для отложенного выполнения операций. Очевидно, что это замедляет операцию фиксации, но существенно упрощает процедуры ее отмены и восстановления. Примером реализаций ТП, использующих данную политику, являются RSTM-LLT \cite{rstm_proj} и RSTM-RingSW \cite{spear_strategy_for_cm, spear_ringstm}.

\textit{Ранняя политика обновления} (eager version management) предполагает, что все изменения объектов сразу записываются в память. В журнале отката (undo log) фиксируются все выполненные операции с памятью. Он используется для восстановления оригинального состояния модифицируемых участков памяти в случае возникновения конфликта. Эта политика характеризуется быстрым выполнением операции фиксации транзакции, но медленным выполнением процедуры ее отмены. Примерами реализаций, использующих раннюю политику обновления данных, являются GCC (libitm), TinySTM \cite{felber_fetzer_marlier_riegel}, LSA-STM \cite{riegel_felber_fetzer}, Log-TM \cite{kevin_bobba_logtm}, RSTM \cite{rstm_proj} и др.
 
Момент времени, когда инициируется алгоритм обнаружения конфликта, определяется \textit{стратегией обнаружения конфликтов}. При \textit{отложенной стратегии} (lazy conflict detection) алгоритм обнаружения конфликтов запускается на этапе фиксации транзакции \cite{spear_ringstm}. Недостатком этой стратегии является то, что временной интервал между возникновением конфликта и его обнаружением может быть достаточно большим. Эта стратегия используется в RSTM-LLT \cite{rstm_proj} и RSTM-RingSW \cite{rstm_proj, spear_strategy_for_cm, spear_ringstm}. 

\textit{Пессимистичная стратегия обнаружения конфликтов}(eager conflict detection) запускает алгоритм их обнаружения при каждой операции обращения к памяти. Такой подход позволяет избежать недостатков отложенной стратегии, но может привести к значительным накладным расходам, а также, в некоторых случаях, может привести к увеличению числа откатов транзакций. Стратегия реализована в TinySTM \cite{felber_fetzer_marlier_riegel}, LSA-STM \cite{riegel_felber_fetzer} и TL2 \cite{dice_shavit_tl2}. В компиляторе GCC (libitm) реализован комбинированный подход к обнаружению конфликтов --отложенная стратегия используется совместно с пессимистической.

\section{Задача о предотвращении возникновения ложных конфликтов}
\subsection{Определение ложных конфликтов}
Для обнаружения конфликтных операций требуется отслеживать изменения состояния используемых областей памяти. Информация о состоянии может соответствовать областям памяти различной степени гранулярности. Выбор гранулярности обнаружения конфликтов -- один из ключевых моментов при реализации программной транзакционной памяти.

На сегодняшний день используются два уровня гранулярности: \textit{уровень программных объектов} (object-based STM) и \textit{уровень слов памяти} (word-based STM). Уровень программных объектов подразумевает отображение объектов модели памяти языка (объекты C++, Java, Scala) на метаданные runtime-библиотеки. При использовании уровня слов памяти осуществляется отображение блоков линейного адресного пространства процесса на метаданные. Метаданные хранятся в таблице, каждая строка которой соответствует объекту программы или области линейного адресного пространства процесса. В строке содержатся номер транзакции, выполняющей операцию чтения/записи памяти; номер версии отображаемых данных; их состояние и др. Модификация метаданных выполняется runtime-системой с помощью атомарных операций процессора.

Реализация программной транзакционной памяти в компиляторе GCC использует уровень слов памяти, в которых размер блока по умолчанию равен 16 байт.

На Рисунке~\ref{img:metadata_gcc_exm} представлен пример организации метаданных транзакционной памяти с использованием уровня слов памяти (GCC 4.7+). Линейное адресное пространство процесса фиксированными блоками циклически отображается на строки таблицы, подобно кэшу прямого отображения. Выполнение операции записи приведет к изменению поля <<состояние>> соответствующей строки таблицы на <<заблокировано>>. Доступ к области линейного адресного пространства, у которой соответствующая строка таблицы помечена как <<заблокировано>>, приводит к конфликту.

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {stm/metadata_gcc_exm}
  \caption{Таблица с метаданными GCC 4.7+ (word-based STM): $B = 16$, $S = 2^{19}$}
  \label{img:metadata_gcc_exm}  
\end{figure}

Основными параметрами транзакционной памяти с использованием уровня слов памяти являются число $S$ строк таблицы и количество $B$ адресов линейного адресного пространства, отображаемых на одну строку таблицы. От выбора этих параметров зависит число ложных конфликтов -- ситуаций аналогичных ситуации ложного разделения данных при работе кэша процессора. В текущей реализации GCC (4.7-5.1) эти параметры фиксированы \cite{felber_fetzen_riegel_dynamic_performance_tuning}. 

При отображении блоков линейного адресного пространства процесса на метаданные runtime-библиотеки возникают коллизии. Это неизбежно, так как размер таблицы метаданных гораздо меньше размера линейного адресного пространства процесса. Коллизии приводят к возникновению ложных конфликтов. \textit{Ложный конфликт} -- ситуация, при которой два или более потока во время выполнения транзакции обращаются к разным участкам линейного адресного пространства, но сопровождаемым одними и теми же метаданными о состоянии, и как минимум один поток выполняет операцию записи. Таким образом, ложный конфликт -- это конфликт, который происходит не на уровне данных программы, а на уровне метаданных runtime-библиотеки.

Возникновение ложных конфликтов приводит к откату транзакций так же, как и возникновение обычных конфликтов, несмотря на то что состояние гонки за данными не возникает, что влечет за собой увеличение времени выполнения STM-программ. Сократив число ложных конфликтов, можно существенно уменьшить время выполнения программы.

На рис. \ref{img:false_conf_exm} показан пример возникновения ложного конфликта в результате коллизии отображения линейного адресного пространства на строку таблицы. Поток 1 при выполнении операции записи над областью памяти с адресом $A1$ захватывает соответствующую строку таблицы. Выполнение операции чтения над областью памяти с адресом $A2$ потоком 2 приводит к возникновению конфликта, несмотря на то что операции чтения и записи выполняются над различными адресами. Последнее обусловлено тем, что 1 и 2 отображены на одну строку таблицы метаданных.

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {stm/false_conf_exm}
  \caption{Пример возникновения ложного конфликта при выполнении двух транзакций (GCC 4.7+)}
  \label{img:false_conf_exm}
\end{figure}

\subsection{Предотвращение возникновения ложных конфликтов методом реорганизации таблицы методанных}

В работе \cite{zilles_rajwar_false_conf} для минимизации числа ложных конфликтов предлагается использовать вместо таблицы с прямой адресацией (как в GCC 4.7+), в которой индексом является часть линейного адреса, хеш-таблицу, коллизии в которой разрешаются методом цепочек. В случае отображения нескольких адресов на одну запись таблицы каждый адрес добавляется в список и помечается тэгом для идентификации (рис. 5). Такой подход позволяет избежать ложных конфликтов, однако накладные расходы на синхронизацию доступа к метаданным существенно возрастают, так как значительно увеличивается количество атомарных операций <<сравнение с обменом>> (compare and swap -- CAS).

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {stm/false_conf_resolv_exm}
  \caption{Хеш-таблица для хранения метаданных без ложных конфликтов}
  \label{img:false_conf_resolv_exm}
\end{figure}



\section{Сокращение возникновения ложных конфликтов по результатам предварительного профилирования}
Автором предложен метод, позволяющий сократить число ложных конфликтов в STM-программах. Предполагается, что метаданные организованы в виде таблицы с прямой адресацией. Суть метода заключается в автоматической настройке параметров $S$ и $B$ таблицы под динамические характеристики конкретной STM-программы. Метод включает три этапа.

\textbf{Этап 1}. Внедрение функций библиотеки профилирования в транзакционные секции. На первом этапе выполняется компиляция C/C++ STM-программы с использованием разработанного модуля анализа транзакционных секций и внедрения вызова функций библиотеки профилирования (модуль расширения GCC). В ходе статического анализа транзакционных секций STM-программ выполняется внедрение кода для регистрации обращений к функциям Intel TM ABI (\texttt{\_ITM\_beginTransaction}, \texttt{\_ITM\_comitTransaction}, \texttt{\_ITM\_LU4}, \texttt{\_ITM\_WU4} и др.). Детали реализации модуля описаны ниже.

\textbf{Этап 2}. Профилирование программы. На данном этапе выполняется запуск STM-программы в режиме профилирования. Профилировщик регистрирует все операции чтения/записи памяти в транзакциях. В результате формируется протокол (trace), содержащий информацию о ходе выполнения транзакционных секций: 
\begin{itemize}
\item адрес и размер области памяти, над которой выполняется операция;
\item временная метка (timestamp) начала выполнения операции.
\end{itemize}

\textbf{Этап 3}. Настройка параметров таблицы. По протоколу определяются средний размер $W$ читаемой/записываемой области памяти во время выполнения транзакций. По значению $W$ подбираются субоптимальные параметры $B$ и $S$ таблицы, с которыми STM-программа компилируется.

\begin{algorithm}[!h]
	\input{listings/STMOptimizeParams.pc}
    \caption{Алгоритм выбора значений параметров $B$ и $S$ (Этап 3)}
    \label{list:STMOptimizeParams.pc}
\end{algorithm}

В Листинге~\ref{list:STMOptimizeParams.pc} представлен псевдокод алгоритма \textsc{STMOptimizeParams} реализующий этап 3. Эксперименты с тестовыми STM-программами из пакета STAMP (6 типов STM-программ) позволили сформулировать эвристические правила для подбора параметров $B$ и $S$ по значению $W$, которое определяется в результате анализа протокола trace (функция \textsc{ProcessTrace}). Функция \textsc{CompileProgram} запускает процесс компиляции с новыми параметрами реализации STM. Значение параметра $S$ целесообразно выбирать из множества $\{2^{18}, 2^{19}, 2^{20}, 2^{21}\}$. Значение параметра $B$ выбирается следующим образом:
\begin{itemize}
\item если $\textit{W} = 1$ байт, то $\textit{B} = 2^{4}$ байт;
\item если $\textit{W} = 4$ байт, то $\textit{B} = 2^{6}$ байт;
\item если $\textit{W} = 8$ байт, то $\textit{B} = 2^{7}$ байт;
\item если $\textit{W} >= 64$ байт, то $\textit{B} = 2^{8}$ байт.
\end{itemize}

\section{Программный инструментарий для сокращения ложных конфликтов}
Автором разработан программный инструментарий (STM false conflict optimizer) для оптимизации ложных конфликтов, возникающих при выполнении параллельных программ с транзакционной памятью. Инструментарий позволяет выполнять профилирование STM-программ. Информация, полученная в результате профилирования, предоставляет достаточно сведений о динамических характеристиках транзакционных секций для того, чтобы ответить на вопрос: <<Фиксации каких транзакций или операции над какими данными приводят к отмене других транзакций?>>. Кроме этого, разработанное программное средство позволяет определить значения субоптимальных значений параметров реализации runtime-системы ТП, а именно число строк таблицы метаданных о состоянии областей памяти и количество адресов линейного адресного пространства, отображаемых на одну строку таблицы.

\subsection{Функциональная структура пакета}
Программный инструментарий состоит из трех основных компонентов (рис. \ref{img:stm_fc_optimizer}):
\begin{itemize}
\item модуль внедрения функций библиотеки профилирования в код транзакционных секций ($tm\_prof\_analyzer$);
\item библиотека профилирования параллельной программы с транзакционной памятью ($libitm\_prof$);
\item модуль анализа протокола выполнения транзакционных секций, установки значений параметров реализации ($tm\_proto\_analyzer$).
\end{itemize}

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {stm/stm_fc_optimizer}
  \caption{Функциональная структура разработанного 
пакета; $1$ -- компиляция STM-программы; $2$ -- запуск STM-программы под 
управление профилировщика; $3$ -- обращение к функциям профилировщика}
  \label{img:stm_fc_optimizer}  
\end{figure}

\subsection{Внедрение функций профилировщика}
STM-компилятор осуществляет трансляцию транзакционных секций в последовательность вызовов функций runtime-системы поддержки TM~\cite{olszewski_cutler_judostm}. Компания Intel предложила спецификацию ABI для runtime-систем поддержки транзакционной памяти -- Intel~TM~ABI~\cite{intel_tm_abi}. Компилятор GCC, библиотека libitm, реализует этот интерфейс начиная с версии 4.7. В Листинге~\ref{list:gcc_transform_exm.pc} представлен пример трансляции компилятором GCC транзакционной секции в обращения к функциям Intel TM ABI.

\begin{ListingEnv}[!h]
  \lstinputlisting[style=customc, belowskip=1\baselineskip]{listings/gcc_transform_exm_top.pc}
  \lstinputlisting[style=customc]{listings/gcc_transform_exm_bottom.pc}
    \caption{Трансляция транзакционной секции компилятором GCC; код вверху -- исходная транзакционная секция; код внизу -- промежуточное представление трансформированной транзакционной секции}
    \label{list:gcc_transform_exm.pc}
\end{ListingEnv}

В общем случае последовательность выполнения транзакции следующая:
\begin{enumerate}
\item Создание транзакции (вызов \_ITM\_beginTransaction) и анализ ее состояния. Если состояние транзакции содержит флаг принудительной отмены, то выполнение продолжается с метки <L3>, т.е. осуществляется выход из транзакции, иначе выполнение тела транзакции начинается с метки <L2>.
\item  Выполнение транзакции. Если выполняется принудительная отмена транзакции, то в состоянии устанавливается флаг принудительной отмены (a\_abortTransaction) и управление передается метке <L1>.
\item Попытка фиксации транзакции (вызов \_ITM\_commitTransaction). В случае возникновения конфликта транзакция отменяется, в состояние транзакции записывается причина отмены и выполнение транзакции повторяется начиная с метки <L1>.
\end{enumerate}

Разработанный модуль $tm\_prof\_analyzer$ внедрения функций библиотеки профилирования выполнен в виде встраиваемого модуля компилятора GCC. Программист компилирует STM-программу с ключом $-fplugin=tm\_prof\_analyzer.so$. Модуль внедрения выполняет анализ промежуточного представления $GIMPLE$ транзакционных секций и добавляет функции регистрации обращений к функциям Intel TM ABI: регистрация начала транзакции и ее фиксации, транзакционное чтения/запись областей памяти.

В Листинге~\ref{list:tm_prof_analyzer_exm.pc} представлен пример внедрения вызовов функций библиотеки профилирования в транзакционную секцию. Функции с префиксом $tm\_prof\_$ выполняют регистрацию событий.

\begin{ListingEnv}[!h]
\lstinputlisting[style=customc, belowskip=1\baselineskip]{listings/tm_prof_analyzer_exm_top.pc}
\lstinputlisting[style=customc]{listings/tm_prof_analyzer_exm_bottom.pc}
\caption{Встраивание в транзакционную секцию функций библиотеки профилирования; код вверху -- исходная транзакционная секция; код внизу -- промежуточное представление трансформированной транзакционной секции}
\label{list:tm_prof_analyzer_exm.pc}
\end{ListingEnv}

Во время выполнения STM-программы под управлением профилировщика ($libitm\_prof$), функции регистрации обращений к интерфейсам Intel TM ABI заносят в протокол адреса и размер областей памяти, над которыми выполняются операции, а также время начала выполнения операций. После завершения выполнения STM-программы формируется протокол выполнения программы, на основе которого модуль анализа ($tm\_proto\_analyzer$) осуществляет выбор субоптимальных параметров таблицы метаданных транзакционной памяти.

\section{Экспериментальное исследование метода оптимизации обнаружения конфликтов}
Экспериментальное исследование проводилось на ВС, оснащенной двумя четырехъядерными процессорами Intel Xeon E5420. В данных процессорах отсутствует поддержка аппаратной транзакционной памяти (Intel TSX). В качестве тестовых программ использовались многопоточные STM-программы из пакета STAMP \cite{spear_strategy_for_cm, spear_ringstm, dice_shavit_tl2}. Число потоков варьировалось от 1 до 8. Тесты собирались компилятором GCC 5.1.1. Операционная система GNU/Linux Fedora 21 x86\_64.

В рамках экспериментов измерялись значения двух показателей:
\begin{itemize}
\item время $t$ выполнения STM-программы;
\item количество $C$ ложных конфликтов в программе.
\end{itemize}

На Рисунках~\ref{graph:C_N_constS},~\ref{graph:C_N_constB},~\ref{graph:t_N_constS},~\ref{graph:t_N_constB} показана зависимость количества $C$ ложных конфликтов и времени $t$ выполнения теста от числа потоков при различных значениях параметров $B$ и $S$. Результаты приведены для программы genome из пакета STAMP. В ней порядка 10 транзакционных секций, реализующих операции над хеш-таблицей и связными списками. Видно, что увеличение значений параметров $S$ и $B$ приводит к уменьшению числа возможных коллизий (ложных конфликтов), возникающих при отображении адресов линейного адресного пространства процесса на записи таблицы. При размере таблицы $2^{21}$ записей, на каждую из которых отображается $2^{6}$ адресов линейного адресного пространства, достигается минимум времени выполнения теста genome, а также минимум числа ложных конфликтов.

\begin{figure}
    \centering
	\subcaptionbox{$S = 2^{19}$ \label{graph:C_N_constS}}
	{\includegraphics[width=0.5\linewidth]{stm/C_N_constS}}%
	\subcaptionbox{$B = 2^6$\label{graph:C_N_constB}}
	{\includegraphics[width=0.5\linewidth]{stm/C_N_constB}}
    \caption{Число $C$ ложных конфликтов}
    \label{graph:C_N}
\end{figure}

\begin{figure}
    \centering
	\subcaptionbox{$S = 2^{19}$ \label{graph:t_N_constS}}
	{\includegraphics[width=0.5\linewidth]{stm/t_N_constS}}%
	\subcaptionbox{$B = 2^6$\label{graph:t_N_constB}}
	{\includegraphics[width=0.5\linewidth]{stm/t_N_constB}}
    \caption{Время $t$ выполнения теста}
    \label{graph:t_N}
\end{figure}

Время выполнения теста genome удалось сократить в среднем на 20\% за счет 
минимизации числа ложных конфликтов.

\section{Оптимизация выполнения циклов}
\subsection{Архитектурные возможности ускорения вычислений}
Для эффективного использования ресурсов многоядерного процессора современные компиляторы применяют машинно-независимые техники оптимизации программ [2]. Такие техники либо полностью игнорируют ресурсы процессора, либо представляют их моделью, которая не учитывает архитектурные возможности [4]. Существует три основных типа машинно-независимых техник оптимизации: автоматическая векторизация кода, конвейеризация циклов и планирование команд [2, 6, 7, 10]. Однако, чтобы повысить эффективность выполнения вычислений на современных процессорах, требуется учитывать архитектурные и микроархитектурные возможности [5, 8, 9].

\textbf{Параллелизм команд на уровне АЛУ ядра и микроархитектурные возможности ускорения вычислений.}
Современные процессоры являются многоядерными и, как правило, обладают суперскалярной архитектурой с конвейерным принципом выполнения команд [1]. Основная идея конвейерной архитектуры заключается в разбиении выполнения команд процессора на несколько простых стадий. Следующая команда начнет своё выполнение после завершения выполнения нескольких стадий текущей команды, а не после её окончательного выполнения.

Суперскалярная архитектура подразумевает наличие в вычислительном ядре процессора нескольких АЛУ, способных одновременно выполнять команды (\textit{параллелизм на уровне команд}, \textit{instruction level parallelism}).

Способ организации архитектуры набора команд в процессоре принято называть микроархитектурой. Микроархитектура современных процессоров является суперскалярной и реализует принцип конвейерного выполнения команд. На рис. 1 представлена функциональная структура Skylake микроархитектуры вычислительного ядра, которая используется в процессорах Intel Core 6-го поколения [11, 12]. 
Функциональную структуру вычислительного ядра с микроархитектурой Skylake можно условно разделить на 2 логических блока: конвейер верхнего уровня (Frontend) и суперскалярный конвейер нижнего уровня (Backend) [11]. Конвейер верхнего уровня выбирает CISC-команды из L1 кэша команд, при помощи устройства декодирования (Legacy Decode Pipeline) преобразует в микрокоманды (RISC-команды) и помещает в очередь декодированных микрокоманд (Instruction Decode Queue -- IDQ). Пропускная способность устройства декодирования составляет 5 команд, а ёмкость очереди 64 микрокоманды.
Суперскалярный конвейер нижнего уровня состоит из функциональных устройств (Port 0-7) которые реализуют выполнение арифметических и логических операций, загрузки данных в регистры и сохранение значений регистров в память, управляющие и системные команды. Функциональные устройства, также, организованы по принципу конвейерной обработки данных.
Наличие нескольких функциональных устройств позволяет выполнять микрокоманды, независящие по данным, одновременно (параллелизм на уровне команд). Микроархитектура Skylake может выдавать до 8 микрокоманд за такт.
Функциональным устройствам выдаются только готовые для выполнения микрокоманды. Микрокоманда считается готовой для выполнения, если её операнды загружены из памяти в регистры. Если такие микрокоманды отсутствуют, то конвейер свободных функциональных устройств простаивает и ничего не выполняет. Для максимального задействования всех имеющихся функциональных устройств в конвейере вычислительного ядра имеется динамических планировщик, реализующий парадигму внеочередного выполнения микрокоманд (Out-of-order execution). Данная парадигма позволяет сократить время простоя конвейеров функциональных устройств и в большей степени задействовать микроархитектурные возможности для ускорения вычислений.

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {march/skylake}
  \caption{Функциональная структура микроархитектуры Skylake}
  \label{img:skylake}
\end{figure}

Динамический планировщик выбирает готовые микрокоманды из очереди и направляет свободным функциональным устройствам для выполнения. Алгоритм выбора планировщиком готовых микрокоманд должен не только максимальным образом задействовать параллелизм на уровне команд и использовать микроархитектурные возможности для ускорения вычислений, но и сохранить семантику выполняемого кода. Динамические планировщики многих современных процессоров реализуют алгоритм Томасуло [13].

\textbf{Параллелизм данных на уровне векторных АЛУ вычислительного ядра.}
Наряду с параллелизмом уровня команд вычислительные ядра современных процессоров реализуют параллелизм уровня данных благодаря наличию векторных АЛУ. Наборы команд практически всех архитектур современных процессоров включают поддержку векторных команд: Intel SSE/AVX/AVX-512, ARM NEON SIMD, IBM AltiVec, MIPS MSA. Процессоры, реализующие поддержку таких команд, содержат одно или несколько параллельно работающих векторных АЛУ и совокупность векторных регистров. В отличие от векторных систем 1990-х годов, современные процессоры поддерживают выполнение операций с векторами относительно небольшой длины (64 -- 512 бит), предварительно загруженными из оперативной памяти в векторные регистры (класс векторных систем <<регистр-регистр>>. 
Основная сфера применения векторных инструкций -- сокращение времени работы с одномерными массивами. При векторизации происходит трансформация выполнения итераций обработки массивов данных в векторные инструкции, выполняющиеся одновременно над несколькими экземплярами данных. Как правило, ускорение, достигаемое при использовании векторных инструкций, в первую очередь определяется количеством элементов массива, помещающихся в векторный регистр. Например, каждый из 16 векторных регистров AVX имеет ширину 256 бит, что позволяет загружать в них 16 элементов типа short int (16 бит), 8 элементов типа int или float (32 бита) и 4 элемента типа double (64 бита). Соответственно, при использовании AVX ожидаемое ускорение выполнения операций с массивами типа \texttt{short int} -- 16 раз, \texttt{int} и \texttt{float} -- 8 раз, \texttt{double} -- 4 раза.
Процессоры Intel Xeon Phi поддерживают набор векторных инструкций AVX-512 и содержат 32 векторных регистра шириной 512 бит. Каждое ядро процессора c микроархитектурой Knights Corner содержит одно векторное АЛУ шириной 512 бит, а ядра процессора c микроархитектурой Knights Landing -- два АЛУ. 
Достижение максимального ускорения при векторной обработке требует учета микроархитектурных параметров процессоров. Например, таких как выравнивание на заданную границу начальных адресов массивов, загружаемых в векторные регистры (32 байта для AVX и 64 байта для AVX-512). А также смешанное использование SSE- и AVX-инструкций. В этом случае при переходе от выполнения команд одного векторного расширения к другому процессор сохраняет (при переходе от AVX к SSE) или восстанавливает (в противоположном случае) старшие 128 бит векторных регистров YMM (AVX-SSE transition penalties) [6].
Причиной дополнительного ускорения может являться параллельное выполнение векторных инструкций несколькими векторными АЛУ. Таким образом, эффективно векторизованная версия программы в меньшей степени загружает ряд подсистем суперскалярного конвейера процессора. 
Разработчикам прикладных программ доступны следующие способы использования векторных инструкций: ассемблерные вставки; интринсики (intrinsics); SIMD-директивы компиляторов, стандартов OpenMP, OpenACC; языковые расширения и библиотеки; автоматическая векторизация компилятором.
В данной работе внимание уделено последнему подходу. Автоматическая векторизация циклов компиляторами является одной из наиболее значимых методик их оптимизации. Такой способ векторизации не требует значительной модификации прикладных программ и обеспечивает их переносимость на уровне исходного кода между разными архитектурами процессоров.

\subsection{Инструментарий анализа эффективности использования функциональных устройств вычислительного ядра}
Архитектурно-ориентированная оптимизация программ требует использования средств анализа эффективности использования микроархитектурных возможностей для ускорения вычислений. В ходе выполнения всей программы или определенного участка такие средства должны собирать такую информацию как количество декодированных команд, количество микрокоманд, выданных функциональным устройствам для выполнения, количество процессорных тактов, необходимых для выполнения выделенного участка кода, количество процессорных тактов, в течении которых простаивал конвейер функциональных устройств, количество условных переходов, и др.

Современные процессоры реализуют технологии позволяющие выполнять глубокий анализ эффективности кода программы. В частности, в архитектуру процессоров фирмы Intel внедрены специальные счетчики мониторинга производительности, реализована технология Intel Processor Trace для трассировки выполнения кода программ.%~\ref{11, 12}.

В процессе профилирования и анализа эффективности программ очень важно уменьшить влияние ОС на выполнение кода вычислений. Полностью исключить активность ОС невозможно, так как неизбежно происходят прерывания и исключения, обработка системных вызовов, работа планировщика процессов и многое другое. Активность ОС, которую принято называть \textit{шумом ОС}, затрудняет анализ эффективности кода программ.

Для сокращения влияния шума ОС на анализируемый код разработан инструментарий профилирования программ. На Рисунке~\ref{img:pmc_tools} приведена функциональная структура разработанного профилировщика. Предложенный инструментарий позволяет получить значения счетчиков производительности при выполнении заданного участка для конкретной микроархитектуры. На текущий момент реализована поддержка микроархитектуры Ivy Bridge.

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {march/pmc_tools}
  \caption{Функциональная структура инструментария профилирования}
  \label{img:pmc_tools}
\end{figure}

Профилировщик состоит из модуля ядра Linux и runtime-библиотеки. Модуль ядра Linux запускает механизм отслеживания интересующих событий производительности при установки определенных значений в специальные моделезависимые регистры (Model-Specific Registers, MSR). Выбор событий производительности осуществляется на этапе инициализации профилировщика, а их список для конкретных микроархитектур представлен в.%~\ref{12}.

Runtime-библиотека предоставляет удобный интерфейс для выделения анализируемого участка кода. После выполнения программы результаты профилирования могут быть представлены в виде таблицы.

\subsection{Анализ эффективности подсистем автоматической векторизации циклов в открытых компиляторах}
Для оценки эффективности подсистем векторизации в компиляторах GCC C/C++ и LLVM/Clang в работе использовался пакет Extended Test Suite for Vectorizing Compilers (ETSVC) [2], содержащий основные классы циклов, встречающихся в научных приложениях на языке C. Исходная версия пакета была разработана в конце 1980-х годов группой Дж. Донгарры и содержала 122 цикла на языке Fortran для оценки эффективности компиляторов векторных ВС [3, 4]. В 2011 году группа Д. Падуа транслировала пакет TSVC на язык программирования С и дополнила его новыми циклами [1]. Расширенная версия пакета содержит 151 цикл. Циклы разделены на категории: анализ зависимостей по данным (36 циклов), анализ потока управления и трансформация циклов (52 цикла), распознавание идиоматических конструкций (редукции, рекуррентности и т.п., 27 циклов), полнота понимания языка программирования (23 цикла). Кроме этого, в набор включены 13 контрольных циклов -- тривиальные циклы, с векторизацией которых должен справиться каждый векторизующий компилятор.

Циклы оперируют с одномерными и двумерными глобальными массивами, начальные адреса которых выравнены на заданную границу (по умолчанию 16 байт). Одномерные массивы содержат $125 \cdot 1024 / \text{\texttt{sizeof(TYPE)}}$ элементов заданного типа \texttt{TYPE}, а двумерные -- 256 элементов по каждому измерению. 

Каждый цикл размещен в отдельной функции. Перед выполнением цикла в функции \texttt{init} выполняется инициализация массивов значениями, характерными для данного теста. Внешний цикл используется для увеличения времени выполнения теста (формирования статистики). Вызов пустой функций \texttt{dummy} предотвращает нежелательную оптимизацию внешнего цикла (трансформацию и вынесение внутреннего цикла за пределы внешнего, как инвариантного по отношению к внешнему). После выполнения циклов происходит вычисление и вывод на экран контрольной суммы элементов результирующего массива.

Эксперименты проводились на системе, представляющей собой cервер на базе двух процессоров Intel Xeon E5-2620 v4 (архитектура Intel 64, микроархитектура Broadwell, 8 ядер, Hyper-Threading включен, поддержка набора векторных инструкций AVX 2.0), 64 Гбайта оперативной памяти DDR4, операционная система GNU/Linux CentOS 7.3 x86-64 (ядро linux 3.10.0-514.2.2.el7). 

Анализировалась работа следующих открытых компиляторов: GCC С/C++ 6.3.0, LLVM/Clang 3.9.1. Компиляция векторизованной версии пакета ETSVC выполнялась с опциями, указанными в Таблице~\ref{table:compiler-options} (столбец 2). Для генерации скалярной версии теста опции оптимизации сохранялись, но отключался векторизатор компилятора (столбец 3, Таблице~\ref{table:compiler-options}).

\begin{table}[h!]
\caption{Опции, используемые при компиляции}
\label{table:compiler-options}
\centering
\footnotesize
\begin{tabular}{|C{0.2\linewidth}|C{0.45\linewidth}|C{0.2\linewidth}|}
\hline
\textbf{Компилятор} & Опции компиляции & Отключение векторизатора \\
\hline
%\textbf{Intel C/C++ 17.0} & -O3 -xHost -qopt-report3 
%-qopt-report-phase=vec,loop -qopt-report-embed & -no-vec \\
%\hline
\textbf{GCC C/C++ 6.3.0} & -O3 -ffast-math -fivopts -march=native -fopt-info-vec -fopt-info-vec-missed -fno-tree-vectorize & -fno-tree-vectorize \\
\hline
\textbf{LLVM/Clang 3.9.1} & -O3 -ffast-math -fvectorize -Rpass=loop-vectorize -Rpass-missed=loop-vectorize -Rpass-analysis=loop-vectorize & -fno-vectorize \\
\hline
%\textbf{PGI C/C++ 16.10} & -O3 -Mvect -Minfo=loop,vect -Mneginfo=loop,vect & -Mnovect \\
%\hline
\end{tabular}
\end{table}

Глобальные массивы в пакете ETSVC были выравнены на границу 32 байта. Эксперименты выполнены для массивов с элементами типов \texttt{double}, \texttt{float}, \texttt{int} и \texttt{short int}.
На Рисунке~\ref{img:vectorization-compilers-results} представлены результаты для данных типа \texttt{double}. Для GCC С/C++ общее количество векторизованных циклов составляет 79. При этом 34 из них были векторизованы только им. LLVM/Clang векторизовал 51 цикл, 6 из которых смог векторизовать только он. Количество невекторизованных циклов ни одним из компиляторов составило 66. Результаты векторизации для массивов с элементами типов \texttt{float}, \texttt{int} и \texttt{short int} аналогичны \texttt{double} для обоих компиляторов.

%\begin{sidewaysfigure}
\begin{figure}[!h] 
  \centering
  \includegraphics[scale=0.52]{vect/compilers_results}
  \caption{Результаты векторизации циклов (архитектура Intel 64, тип данных \texttt{double})}
  \label{img:vectorization-compilers-results}
\end{figure}
%\end{sidewaysfigure} 

Таблица~\ref{table:abbr} содержит расшифровку сокращенных обозначений в результатах векторизации на Рисунке~\ref{img:vectorization-compilers-results}. В категории <<Анализ зависимостей по данным>> для типа данных \texttt{double} не были векторизованы ни одним из компиляторов 14 циклов. Проблемными в этой категории оказались циклы, содержащие линейные зависимости (рекуррентности 1-го порядка), непоследовательный доступ к элементам массива, индуктивные переменные в сочетании с условными и безусловными (\texttt{goto}) переходами внутри цикла, вложенностью циклов и переменными значениями нижней и(или) верхней границы цикла и(или) шага выполнения итераций. В последнем случае на этапе статической компиляции ни один из компиляторов не может принять однозначного решения о наличии зависимости по данным и принимает пессимистическое решение о том, что зависимость существует.

В категории <<Анализ потока управления и трансформация циклов>> сложными для векторизации оказались 29 циклов, требующие выполнения следующих преобразований: расщепление тела цикла, перестановка циклов, расщепление вершин в графе зависимостей по данным (для устранения контура в графе и как следствие исключения выходных зависимостей и антизависимостей в цикле [7]) и растягивание скаляров и массивов. Среди причин неудач компиляторов: зависимость значений переменных-счетчиков итераций вложенных циклов друг от друга; линейные зависимости в теле цикла (рекуррентности 1-го порядка); условные и безусловные переходы в теле цикла; охватывающие (wraparound) переменные.

Следующие идиоматические конструкции из категории <<Распознавание идиоматических конструкций>> оказались проблемными при векторизации 15 циклов: рекуррентности 1-го и 2-го порядков, поиск элемента в массиве, свертка цикла и редукция с вызовом функции. Причина невекторизации циклов, содержащих рекуррентные отношения, заключается в наличии линейной зависимости по данным. В цикле, осуществлявшем поиск первого элемента в массиве, удовлетворяющего заданному условию, проблема возникла из-за прерывания вычислений в цикле безусловным переходом \texttt{goto}.

Над циклами, для которых была выполнена раскрутка (unrolling) вручную, компиляторы выполняют операцию свертки (rerolling) прежде, чем приступить к векторизации [8]. Исследуемые компиляторы приняли решение, что векторизация таких циклов возможна, но будет неэффективной. Причиной этого является использование косвенной адресации при обращении к элементам массива: \texttt{X[Y[i]]}, где \texttt{X} -- одномерный массив типа \texttt{float}, \texttt{Y} -- указатель на целочисленный одномерный массив, \texttt{i} -- переменная-счетчик итераций цикла.

Еще одна идиоматическая конструкция, вызвавшая проблемы с векторизацией -- редукция, а именно нахождение суммы элементов одномерного массива. Здесь причиной невекторизации является наличие вызовов функции \texttt{test}, вычисляющей сумму 4-х элементов, начиная с того, который был ей передан в качестве аргумента. 

Категория <<Полнота понимания языка программирования>> содержит 6 невекторизованных ни одним из компиляторов цикла. Проблемы в циклах: прерывание вычислений (вызов функции \texttt{exit}или \texttt{break}), использование оператора \texttt{switch}, условные переходы и косвенная адресация при доступе к элементам массивов. Векторизаторы, реализованные в компиляторах, не смогли выполнить анализ потока управления.

Среди контрольных циклов не были векторизованы ни одним из компиляторов 2, в которых реализовано поэлементное копирование двух одномерных массивов с использованием косвенной адресации.

\begin{table}[h!]
\caption{Сокращенные обозначения результатов векторизации}
\label{table:abbr}
\centering
\footnotesize
\begin{tabular}{|C{0.04\linewidth}|L{0.9\linewidth}|}
\hline
\cellcolor{green!25!gray}V & Цикл векторизован полностью \\
\hline
\cellcolor{yellow!70}PV & Цикл векторизован частично (расщепление тела цикла с последующей векторизацией некоторых из полученных циклов) \\
\hline
\cellcolor{red!50}RV & Остаток цикла (remainder) не векторизован\\
\hline
\cellcolor{red!50}IF & Векторизация возможна, но не эффективна\\
\hline
\cellcolor{red!50}D & Зависимость по данным препятствует векторизации (предполагаемая линейная или нелинейная зависимость по данным в цикле)\\ 
\hline
\cellcolor{red!50}M & Сгенерировано несколько версий цикла, из которых в процессе выполнения программы будет выбрана невекторизованная (multiversioning)\\  
\hline
\cellcolor{red!50}BO & Неподходящая операция или неподдерживаемая форма границы цикла (например, при использовании функций \texttt{sinf} и \texttt{cosf})\\
\hline
\cellcolor{red!50}AP & Сложный шаблон доступа к элементам массива (например, величина шага по индексу больше 1)\\ 
\hline
\cellcolor{red!50}R & Значение, которое не может быть идентифицировано как результат редукции, используется вне цикла (наличие индуктивных переменных)\\ 
\hline
\cellcolor{red!50}IL & Переменная-счетчик внутреннего цикла не является инвариантом (например, переменная-счетчик внутреннего цикла зависит от переменной-счетчика внешнего цикла)\\
\hline
\cellcolor{red!50}NI & Невозможно вычислить количество итераций (нижняя и(или) верхняя граница цикла заданы аргументами функции)\\
\hline
\cellcolor{red!50}CF & Невозможно определить направление потока управления (условные переходы внутри цикла)\\
\hline
\cellcolor{red!50}SS & Цикл не подходит для векторной записи по несмежным адресам (scatter store, например, в случае упаковки двумерного массива в одномерный)\\ 
\hline
\cellcolor{red!50}ME & Цикл с несколькими выходами невозможно векторизовать (наличие \texttt{break} или \texttt{exit} внутри цикла)\\ 
\hline
\cellcolor{red!50}FC & Цикл содержит вызовы функций или данные, которые невозможно проанализировать\\  
\hline
\cellcolor{red!50}OL & Значение не может быть использовано за пределами цикла (растягивание скаляров или использование одномерных и двумерных массивов в одном цикле)\\
\hline
\cellcolor{red!50}UV & Векторизатор не может понять поток управления в цикле (условные переходы внутри цикла)\\
\hline
\cellcolor{red!50}SW & Наличие оператора \texttt{switсh} в цикле\\
\hline
\cellcolor{red!50}US & Неподдерживаемое использование в выражении (растягивание скаляров, распознавание охватывающих переменных)\\
\hline
\cellcolor{red!50}GS & В базовом блоке нет сгруппированных операций записи (развернутое скалярное произведение)\\  
\hline
\end{tabular}
\end{table} 

Максимальное ускорение, полученное при векторизации компилятором GCC С/C++, составило 4.06, 8.1, 12.01 и 24.48 для типов \texttt{double}, \texttt{float}, \texttt{int} и \texttt{short int}, соответственно. Компилятором LLVM/Clang получены следующие значения максимального ускорения: 5.12 (\texttt{double}), 10.22 (\texttt{float}), 4.55 (\texttt{int}) и 14.57 (\texttt{short int}). Ускорение измерялось как отношение времени выполнения скалярного кода к времени выполнения векторизованного. При этом учитывались только значения ускорения, большие 1.15. Как показал анализ, значения максимального ускорения соответствуют циклам, выполняющим операции редукции (сумма, произведение, поиск минимального или максимального элемента) над элементами одномерных массивов всех типов данных. Эти циклы относятся в ETSVC к категории <<Распознавание идиоматических конструкций>>.

\subsection{Экспериментальное исследование возможностей микроархитектурной оптимизации кода}
Анализ микроархитектурных возможностей для ускорения вычислений выполнен на примере оптимизации выполнения функции SAXPY. Функция SAXPY выполняет сумму двух векторов со скалярным произведением константы и одного из слагаемых. Экспериментальное исследование выполнено на целевом процессоре Intel Core i5 -- 3320M с микроархитектурой Ivy Bridge.

Функциональная структура микроархитекутуры Ivy Bridge [11] показана на Рисунке~\ref{img:ivybridge}. Ivy Bridge содержит 6 параллельных функциональных устройств (ФУ), что позволяет отправлять на выполнение до 6 микрокоманд за один такт. 2 из 6 ФУ осуществляют загрузку данных из памяти в регистр и 1 ФУ выполняет сохранение значения регистра в память. Оставшиеся 4 ФУ реализуют арифметические и логические операции.

Конвейер верхнего уровня микроархитектуры Ivy Bridge способен декодировать до 4 команд за такт. Декодированные команды помещаются в кэш декодированных команд емкостью 1536 микрокоманд. 

Для максимально эффективного задействования всех имеющихся ФУ имеется динамический планировщик. Он выбирает готовые для выполнения микрокоманды из очереди декодированных. Очередь декодированных команд может хранить до 28 микрокоманд.

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {march/ivybridge}
  \caption{Функциональная структура микроархитектуры Ivy Bridge}
  \label{img:ivybridge}
\end{figure}

\begin{ListingEnv}[!ht]
	\lstinputlisting[style=customc, belowskip=1\baselineskip]{listings/march/c-saxpy-scalar.c}
	\lstinputlisting[style=custom_asm]{listings/march/asm-saxpy-scalar.s}
    \caption{Скалярная версия реализации функции SAXPY}
    \label{list:saxpy-scalar}
\end{ListingEnv}

\begin{table} [!ht]
  \centering
  \captionsetup{width=15cm}
  \caption{Значения счетчиков производительности для скалярной версии функции SAXPY
  $(y[i] = a \cdot x[i] + y[i]; n = 100000)$}\label{table:perf-saxpy-scalar}%
\begin{tabular}{  | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.13\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.09\linewidth}l | }
\hline
\hline
\input{Dissertation/tables/perf-scalar.txt}
\hline
\hline
  \end{tabular}
\end{table}

В Листинге~\ref{list:saxpy-scalar} приведен пример реализации скалярной версии функции SAXPY на языке \texttt{C} и её скомпилированный код на языке \texttt{Assembler}. Данная реализация на каждой итерации выполняет 2 команды загрузки данных из памяти в регистр, 1 команду сохранения значения регистра в память, по 1 команде умножения и сложения для вычисления SAXPY. Для организации цикла на каждой итерации требуется выполнить 1 команду сложения для увеличения счетчика на 1, 1 команду сравнения содержимого регистров и 1 команду условного перехода. В Таблице~\ref{table:perf-saxpy-scalar} представлены значения счетчиков производительности процессора, полученные при выполнении кода из Листинга~\ref{list:saxpy-scalar}.

\begin{ListingEnv}[!ht]
	\lstinputlisting[style=customc, belowskip=1\baselineskip]{listings/march/c-vectorized-code.c}
	\lstinputlisting[style=custom_asm]{listings/march/asm-vectorized-code.s}
    \caption{Векторная версия реализации функции SAXPY}
    \label{list:saxpy-vector-sse}
\end{ListingEnv}

\begin{table} [!h]
  \centering
  \captionsetup{width=15cm}
  \caption{Значения счетчиков производительности для векторной версии функции SAXPY
  $(y[i] = a \cdot x[i] + y[i]; n = 100000)$}\label{table:perf-saxpy-vector-sse}%
\begin{tabular}{  | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.13\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.09\linewidth}l | }
\hline
\hline
\input{Dissertation/tables/perf-vectorized.txt}
\hline
\hline
  \end{tabular}
\end{table}

Цикл из Листинга~\ref{list:saxpy-scalar} легко векторизуется. В Листинге~\ref{list:saxpy-vector-sse} представлена реализация векторизованной версии функции SAXPY при помощи набора инструкций \texttt{SSE}. Команды сложения и умножения, а также команды загрузки данных из памяти в регистр и сохранения значения регистров в память выполняются с регистрами шириною 128 бит. При условии последовательного выполнения команд теоретически может быть достигнуто максимальное ускорение до 4 раз от использования набора команд \texttt{SSE}. Однако, на практике, после векторизации функции, удалось достигнуть ускорения приблизительно в 2 раза. В Таблице~\ref{table:perf-saxpy-vector-sse} приведены значения счетчиков производительности процессора, полученные при выполнении векторизованной функции SAXPY.

Анализ микроархитекты Ivy Bridge показал, что команды \texttt{mulps} и \texttt{addps} могут выполняться разными ФУ параллельно. Однако, использование параллелизма уровня команд в случае вычисления функции SAXPY невозможно, так как присутствует зависимость по данным между командами \texttt{mulps} и \texttt{addps}.

\begin{ListingEnv}[!ht]
	\lstinputlisting[style=custom_asm]{listings/march/asm-vectorized-pipelined-code.s}
    \caption{Конвейеризация векторной версии реализации функции SAXPY}
    \label{list:saxpy-vector-sse-pipelined}
\end{ListingEnv}

\begin{table} [!h]
  \centering
  \captionsetup{width=15cm}
  \caption{Значения счетчиков производительности для конвейеризированной векторной 
версии функции SAXPY $(y[i] = a \cdot x[i] + y[i]; n = 100000)$}\label{table:perf-saxpy-vector-sse-pipelined}%
\begin{tabular}{  | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.13\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.09\linewidth}l | }
\hline
\hline
\input{Dissertation/tables/perf-vectorized-pipelined.txt}
\hline
\hline
  \end{tabular}
\end{table}

\begin{ListingEnv}[!ht]
	\lstinputlisting[style=custom_asm]{listings/march/asm-vectorized-pipelined-unrolled-code.s}
    \caption{Конвейеризация векторной версии реализации функции SAXPY с раскрученным циклом на 2 итерации}
    \label{list:saxpy-vector-sse-pipelined-unrolled}
\end{ListingEnv}

\begin{table} [!h]
  \centering
  \captionsetup{width=15cm}
  \caption{Значения счетчиков производительности для конвейеризированной векторной 
версии функции SAXPY с раскрученным циклом на 2 итерации 
$(y[i] = a \cdot x[i] + y[i]; n = 100000)$}\label{table:perf-saxpy-vector-sse-pipelined-unrolled}%
\begin{tabular}{  | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.13\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.09\linewidth}l | }
\hline
\hline
\input{Dissertation/tables/perf-vectorized-pipelined-unrolled.txt}
\hline
\hline
  \end{tabular}
\end{table}

Конвейеризация цикла \texttt{for} функции SAXPY, представленной в Листинге~\ref{list:saxpy-vector-sse}, позволит избавиться от зависимости по данным между командами \texttt{mulps} и \texttt{addps}. Листинг~\ref{list:saxpy-vector-sse-pipelined} содержит код конвейеризированной версии цикла. На каждой итерации команда \texttt{mulps} выполняется над данными $i$-ой итерации цикла, а команд \texttt{addps} и сохранение результата -- над данными $i-1$ итерации. Данное преобразование цикла не нарушает оригинальную семантику программы, так как отсутствует зависимость по данным между итерациями цикла. Однако, требуется наличие пролога и эпилога цикла для подготовки операндов нулевой итерации и сохранения результата последней итерации.

В Таблице~\ref{table:perf-saxpy-vector-sse-pipelined} приведены значения счетчиков производительности процессора, полученными во время выполнения реализации из Листинга~\ref{list:saxpy-vector-sse-pipelined}. После конвейеризации цикла время выполнения программы удалось сократить на 6\% по сравнению с векторной версией SAXPY, приведенной в Листинге~\ref{list:saxpy-vector-sse}.

В реализации SAXPY из Листинга~\ref{list:saxpy-vector-sse-pipelined} присутствует одно избыточное перемещение значения из регистра \texttt{xmm1} в \texttt{xmm2} (Листинг~\ref{list:saxpy-vector-sse-pipelined} строка 10). Раскрутка цикла на 2 итерации позволит избежать это перемещение. Результат трансформации цикла приведен в Листинге~\ref{list:saxpy-vector-sse-pipelined-unrolled}. Данное преобразование позволило сократить время выполнения функции SAXPY на 11\% по сравнению с конвейеризированной версией Листинга~\ref{list:saxpy-vector-sse-pipelined}. Таблица~\ref{table:perf-saxpy-vector-sse-pipelined-unrolled} содержит значения счетчиков производительности процессора для данной версии.

\begin{ListingEnv}[h!t]
	\lstinputlisting[style=customc, belowskip=1\baselineskip]{listings/march/c-avx-code.c}
	\lstinputlisting[style=custom_asm]{listings/march/asm-avx-code.s}
    \caption{\texttt{AVX} версия реализации функции SAXPY}
    \label{list:saxpy-vector-avx}
\end{ListingEnv}

\begin{table} [!h]
  \centering
  \captionsetup{width=15cm}
  \caption{Значения счетчиков производительности для AVX версии функции SAXPY
  $(y[i] = a \cdot x[i] + y[i]; n = 100000)$}\label{table:perf-saxpy-vector-avx}%
\begin{tabular}{  | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.13\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} | p{0.09\linewidth} |
p{0.09\linewidth}l | }
\hline
\hline
\input{Dissertation/tables/perf-avx.txt}
\hline
\hline
  \end{tabular}
\end{table}

Кроме набора инструкций \texttt{SSE} микроархитектура Ivy Bridge поддерживает расширение архитектуры набора команд \texttt{AVX}, которое позволяет выполнять векторные команды над регистрами шириною 256 бит, что вдвое больше ширины регистров \texttt{SSE}. Теоретическое максимальное ускорение от использования набора команд \texttt{AVX} составляет 2 раза относительно использования набора инструкций \texttt{SSE}. В Листинге~\ref{list:saxpy-vector-avx} приведена реализация \texttt{AVX} версии функции SAXPY. Использование регистров большей ширины и команд, способных выполнять над ними арифметические операции, не принесло ожидаемого ускорения, так как в данном примере основным фактором, влияющим на ускорение, является загрузка данных из памяти в регистр и сохранение значения регистра в память. Микроархитектура Ivy Bridge содержит 2 ФУ для загрузки данных из памяти в регистр. Пропускная способность каждого ФУ 128 бит за цикл, что делает неэффективным использование 256 битных регистров и команд над ними. В Таблице~\ref{table:perf-saxpy-vector-avx} представлены значения счетчиков производительности процессора после выполнения \texttt{AVX} версии функции SAXPY.

\clearpage
\subsection{Экспериментальное исследование эффективности векторизации алгоритма умножения матриц}
Распространенным шаблоном вычислений в библиотеках линейной алгебры является гнездо из трех циклов $(i = 0 ... M - 1; j = 0 ... N - 1; k = 0 ... K - 1)$, в котором выполняются арифметические операции над элементами двумерных массивов. Здесь $i, j, k$ -- индуктивные переменные, являющиеся счетчиками циклов. Такое гнездо характеризуется наличием инструкций обработки элементов массивов только в самом внутреннем вложенном цикле и пространством итераций, образующим прямоугольный параллелепипед с размерностями $M, N, K$.

Типичным представителем гнезда из трех циклов является алгоритм умножения матриц GEMM, выполняющий вычисления вида: $A = \alpha \cdot B \cdot C + \beta \cdot A$, где $A$, $B$ и $C$ -- двумерные массивы с размерностями $M \times N$, $M \times K$ и $K \times M$, соответственно, а $\alpha$ и $\beta$ -- скалярные коэффициенты. Для алгоритма умножения матриц по определению $\alpha = \beta = 1$. Если $M = N = K, А, B$ и $C$ -- квадратные матрицы. Частным случаем GEMM является алгоритм DGEMM, оперирующий матрицами, элементами которых являются числа с плавающей запятой двойной точности (тип данных \texttt{double}).

Алгоритм умножения матриц DGEMM можно реализовать в виде двух последовательных версий (см. Рисунок~\ref{img:dgemm}). В первой версии циклы выполняются в порядке $i \rightarrow j \rightarrow k$, а во второй -- в порядке $i \rightarrow k \rightarrow j$. На Рисунке~\ref{img:dgemm} порядок следования циклов представлен в виде кортежей из трех индуктивных переменных $<i, j, k>$ и $<i, k, j>$. Каждая из этих версий может быть векторизована тремя способами: 1) только по самому внутреннему вложенному циклу; 2) по среднему вложенному циклу и 3) по обоим этим циклам. На Рисунке~\ref{img:dgemm} в кортежах индуктивная переменная векторизуемого цикла помечена символом <<$\rightarrow$>>. Шаг $S$ выполнения итераций для векторизуемых циклов равен количеству элементов типа данных \texttt{double}, помещающихся в векторный регистр целевой архитектуры вычислительной системы. Например, для архитектуры c короткими векторными регистрами, поддерживающей набор векторных инструкций Intel AVX, $S = 4$. 

\begin{figure}[!h] 
  \center
  \includegraphics [scale=1] {vect/dgemm}
  \caption{Скалярные и векторизованные версии алгоритма умножения матриц DGEMM по определению для двумерных массивов $A[M][N]$, $B[M][K]$ и $C[K][N]$ ($S$ -- количество элементов массивов, помещающихся в векторный регистр)}
  \label{img:dgemm}
\end{figure}

Проведено экспериментальное исследование эффективности предложенных версий алгоритма умножения матриц. Исследование проводилось на двух ВС с общей памятью. Первая ВС укомплектована двумя процессорами Intel Xeon E5-2620 v3 (микроархитектура Haswell), а вторая -- двумя процессорами Intel Xeon E5-2620 v4 (микроархитектура Broadwell). Обе ВС имеют 64 Гбайта ОЗУ.

Для сокращения влияния сторонних факторов на выполнение тестов в ходе экспериментов учитывались особенности NUMA-архитектуры. Запуск процесса, выполняющего тест, производился на том же самом NUMA-узле, на котором происходило выделение памяти.

\begin{figure}
    \centering
	\subcaptionbox{Версия $<i,j,k>$\label{graph:graph_broadwell_1}}
	{\includegraphics[width=0.45\linewidth]{vect/graph_broadwell_1}}%
	\subcaptionbox{Версия $<i,k,j>$\label{graph:graph_broadwell_2}}
	{\includegraphics[width=0.45\linewidth]{vect/graph_broadwell_2}} \\
	 1 -- $<i, \vec{j}, \vec{k}>$ с непоследовательным доступом к элементам матрицы $C$; \\
	 2 -- $<i, \vec{j}, \vec{k}>$ с использованием команды \texttt{vbroadcastsd}; 3 -- $<i, \vec{j}, k>$; \\
	 4 -- $<i, \vec{k}, \vec{j}>$ с использованием команды \texttt{vbroadcastsd}; 5 -- $<i, k, \vec{j}>$; \\
	 6 -- $<i, \vec{k}, \vec{j}>$ с непоследовательным доступом к элементам матрицы $C$;
    \caption{Зависимость ускорение выполнения теста на микроархитектуре Broadwell от размерности матриц}
    \label{graph:graph_broadwell}
\end{figure}

\begin{figure}
    \centering
	\subcaptionbox{Версия $<i,j,k>$\label{graph:graph_haswell_1}}
	{\includegraphics[width=0.45\linewidth]{vect/graph_haswell_1}}%
	\subcaptionbox{Версия $<i,k,j>$\label{graph:graph_haswell_2}}
	{\includegraphics[width=0.45\linewidth]{vect/graph_haswell_2}} \\
	 1 -- $<i, \vec{j}, \vec{k}>$ с непоследовательным доступом к элементам матрицы $C$; \\
	 2 -- $<i, \vec{j}, \vec{k}>$ с использованием команды \texttt{vbroadcastsd}; 3 -- $<i, \vec{j}, k>$; \\
	 4 -- $<i, \vec{k}, \vec{j}>$ с использованием команды \texttt{vbroadcastsd}; 5 -- $<i, k, \vec{j}>$; \\
	 6 -- $<i, \vec{k}, \vec{j}>$ с непоследовательным доступом к элементам матрицы $C$;
	 \caption{Зависимость ускорение выполнения теста на микроархитектуре Haswell от размерности матриц}
    \label{graph:graph_haswell}
\end{figure}

\begin{sidewaystable}
 \raggedright
  \bigskip
%  \captionsetup{width=15cm}
  \caption{Значения счетчиков производительности для микроархитектуры Broadwell ($N = 256$)}\label{table:perf-broadwell-vect}%
  \begin{tabular}[c]{|m{3.6cm}|p{1.3cm}|p{1.8cm}|p{1.5cm}|p{2cm}|p{1.8cm}|p{2cm}|p{2cm}|p{1cm}|p{1.7cm}|p{1.75cm}l|}
  \hline
  \hline
  \input{Dissertation/tables/vect/perf-broadwell.txt}
  \hline
  \end{tabular}
\end{sidewaystable}
\begin{sidewaystable}
 \raggedright
  \bigskip
%  \captionsetup{width=15cm}
   \caption{Значения счетчиков производительности для микроархитектуры Haswell ($N = 64$)}\label{table:perf-haswell-vect}%
  \begin{tabular}[c]{|m{5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.8cm}|p{1cm}|p{1.65cm}|p{1.75cm}l|}
  \hline
  \hline
  \input{Dissertation/tables/vect/perf-haswell.txt}
  \end{tabular}
\end{sidewaystable}

\begin{figure}
	\centering
	\subcaptionbox{Broadwell ($N = 256$)\label{graph:diagram_broadwell_512}}
	{\includegraphics[width=0.45\linewidth]{vect/diagram_broadwell_512}}
	\subcaptionbox{Haswell ($N = 64$)\label{graph:diagram_haswell_64}}
	{\includegraphics[width=0.45\linewidth]{vect/diagram_haswell_64}} \\
	 1 -- $<i, \vec{j}, \vec{k}>$ с непоследовательным доступом к элементам матрицы $C$; \\
	 2 -- $<i, \vec{j}, \vec{k}>$ с использованием команды \texttt{vbroadcastsd}; 3 -- $<i, \vec{j}, k>$; \\
	 4 -- $<i, \vec{k}, \vec{j}>$ с использованием команды \texttt{vbroadcastsd}; 5 -- $<i, k, \vec{j}>$; \\
	 6 -- $<i, \vec{k}, \vec{j}>$ с непоследовательным доступом к элементам матрицы $C$;
    \caption{Диаграмма распределения микрокоманд по портам (ФУ)}
    \label{graph:vect-diagram}
\end{figure}

Графики зависимости ускорения различных реализаций теста DGEMM от количества строк и столбцов $N$ используемых матриц приведены на Рисунке~\ref{graph:graph_haswell} для микроархитектуры Haswell и на Рисунке~\ref{graph:graph_broadwell} для Broadwell. В работе [9] представлены реализации приведенных версий алгоритма DGEMM. Наибольшее ускорение получено версией 1 (Рисунке~\ref{graph:graph_broadwell_1}, \ref{graph:graph_haswell_1}), достигнув максимального значения при размере массивов $64 \times 64$ элемента типа double для микроархитектуры Haswell ($S = 4.67$), и при $256 \times 256$ элементов для Broadwell ($S = 8.79$). В этой версии выполнена векторизация циклов $j$ и $k$. Отличительной особенностью данной реализации является работа с транспонированной матрицей $C$. Это позволило уменьшить количество кэш-промахов при выполнении загрузки данных из L1 кэша (8684 кэш-промахов при $N = 64$, микроархитектура Haswell, и 2115816 кэш-промахов при $N = 256$, микроархитектура Broadwell), а также сократить число операций загрузки и сохранения данных из/в память (86038/1034 load/store операций при $N = 64$, микроархитектура Haswell, и 5308466/16396 load/store операций при $N = 256$, микроархитектура Broadwell). Детальный отчет, содержащий значения счетчиков производительности основных версий алгоритма умножения матриц, приведен в Таблице~\ref{table:perf-haswell-vect} для микроархитектуры Haswell и в Таблице~\ref{table:perf-broadwell-vect} для Broadwell. Количество $V$ микрокоманд, назначенных на ФУ P0-P7 (порты выдачи микрокоманд) вычислительного ядра для микроархитектур  Broadwell и Haswell, показано на Рисунках~\ref{graph:diagram_broadwell_512} и~\ref{graph:diagram_haswell_64} соответственно.

\section{Выводы}
\begin{enumerate}
\item Предложен алгоритм оптимизации обнаружения конфликтов в параллельных программах для многопроцессорных ВС с общей памятью при выполнении транзакционных секций. В отличие от известных алгоритмов, предложенный алгоритм не создаёт накладных расходов во время выполнения STM-программы, так как все действия алгоритма происходят во время компиляции и профилирования.
\item Предложена программная реализация предложенного алгоритма, включающая в себя модуль инструментации транзакционных секций в STM-программе для компилятора GCC, модуль профилирования в runtime-библиотеке \texttt{libitm} для компилятора GCC и модуль выбора параметров реализации программной транзакционной памяти.
\item Выполнено экспериментальное исследование эффективности предложенного алгоритма. Эксперименты показали, что использование предложенного алгоритма позволяет на 20\% сократить время выполнения STM-программы на многопроцессорных ВС с общей памятью.
\item Предложен инструментарий анализа эффективности использования архитектурных возможностей процессора для ускорения вычислений. Отличительным преимуществом предложенного инструментария является возможность выделения, для детального анализа, участка кода в программе с точностью до 1 команды ассемблера, а также снижение влияния <<шума ОС>> на значения счетчиков производительности процессора.
\item Выполнен анализ эффективности подсистем автоматической векторизации циклов в открытых компиляторах GCC и LLVM/Clang. В результате анализа выявлены трудновекторизуемые и не векторизуемые шаблоны циклов.
\item Выполнено экспериментальное исследование архитектурных возможностей ускорения вычислений на многопроцессорных ВС с общей памятью. Используя возможности параллелизма данных на уровне векторных АЛУ было достигнуто ускорение от 4.67 до 8.79 раз. В ходе экспериментов показано, что использование только микроархитектурных возможностей вычислительного ядра процессора позволяет сократить время выполнение параллельной программы на 11\%.
\end{enumerate}

%\newpage
%============================================================================================================================

% \section{Параграф - два} \label{sect3_2}

% Некоторый текст.

%\newpage
%============================================================================================================================

% \section{Параграф с подпараграфами} \label{sect3_3}

%\subsection{Подпараграф - один} \label{subsect3_3_1}

%Некоторый текст.

%\subsection{Подпараграф - два} \label{subsect3_3_2}

%Некоторый текст.

\clearpage


